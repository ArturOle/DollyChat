## Dolly Chat

Simlpe GUI aplication to text and experiment with relatively small LLM Dolly 2.0 3b locally. The project is a personal sandbox to make tests and check new ideas.
Currently, the application is functional and ready for preparation of new features like currently prepared:

- Selection of different models (both local and via API)
- Toolbox for LLMs to be able to perform simple tasks in the computer

To use LLaMA 3.1 70b login to NVIDIA NIM and generate the API key. Save it in the api_key.txt file in the root directory of this project.

To use local Dolly, it needs to be available on the drive and the PATH in model.py neds to be adjusted (for now).

There will be more in the near future.
